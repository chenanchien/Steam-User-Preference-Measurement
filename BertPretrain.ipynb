{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    "\n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if is_torch_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "    if is_tf_available():\n",
    "        import tensorflow as tf\n",
    "\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    df_csv = pd.read_csv('D:/reviewsData/filtered{}.csv'.format(i)).drop(['Unnamed: 0'], axis=1)\n",
    "    if i > 0:\n",
    "        df_csv.index = df_csv.index + len(df)\n",
    "        df = pd.concat([df,df_csv])\n",
    "    else:\n",
    "        df = df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommended_false = df[df['recommended'] == False]['review']\n",
    "recommended_false = df_recommended_false[df_recommended_false.str.len() > 10]\n",
    "df_recommended_true = df[df['recommended'] == True]['review']\n",
    "recommended_true = df_recommended_true[df_recommended_true.str.len() > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_false = pd.DataFrame(recommended_false, columns=['review'])\n",
    "df_true = pd.DataFrame(recommended_true, columns=['review'])\n",
    "df_false['label'] = [0]*len(recommended_false)\n",
    "df_true['label'] = [1]*len(recommended_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_true.loc[df_true.index[:len(df_false)],:],df_false],axis=0,ignore_index=True)\n",
    "train_text, test_text, trainY, testY = train_test_split(df_train['review'].values, df_train['label'].values, test_size=0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = tokenizer(train_text[0:50000].tolist(), truncation=True, padding=True, max_length=512)\n",
    "testX = tokenizer(test_text[0:10000].tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# convert our tokenized data into a torch Dataset\n",
    "\n",
    "train_dataset = ReviewDataset(trainX, trainY[:50000])\n",
    "test_dataset = ReviewDataset(testX, testY[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # calculate accuracy using sklearn's function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='D:/reviewsData/result',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=4,  # batch size per device during training\n",
    "    per_device_eval_batch_size=4,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=500,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 50000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26501' max='37500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26501/37500 6:27:15 < 2:40:44, 1.14 it/s, Epoch 2.12/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.532600</td>\n",
       "      <td>1.341116</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.538700</td>\n",
       "      <td>0.448723</td>\n",
       "      <td>0.874500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>0.428441</td>\n",
       "      <td>0.896600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>0.430204</td>\n",
       "      <td>0.905600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.405596</td>\n",
       "      <td>0.897900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>0.273035</td>\n",
       "      <td>0.906800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.418600</td>\n",
       "      <td>0.335318</td>\n",
       "      <td>0.916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.393500</td>\n",
       "      <td>0.486009</td>\n",
       "      <td>0.889300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>0.374801</td>\n",
       "      <td>0.877100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.386854</td>\n",
       "      <td>0.903100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.408569</td>\n",
       "      <td>0.917400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.295687</td>\n",
       "      <td>0.921900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.367300</td>\n",
       "      <td>0.395976</td>\n",
       "      <td>0.906900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.389100</td>\n",
       "      <td>0.384915</td>\n",
       "      <td>0.916700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.395700</td>\n",
       "      <td>0.473892</td>\n",
       "      <td>0.895100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.295601</td>\n",
       "      <td>0.915400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.393300</td>\n",
       "      <td>0.365551</td>\n",
       "      <td>0.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.342800</td>\n",
       "      <td>0.358726</td>\n",
       "      <td>0.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.388900</td>\n",
       "      <td>0.367384</td>\n",
       "      <td>0.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.360300</td>\n",
       "      <td>0.346748</td>\n",
       "      <td>0.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>0.376677</td>\n",
       "      <td>0.914700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.390500</td>\n",
       "      <td>0.512042</td>\n",
       "      <td>0.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.309350</td>\n",
       "      <td>0.916900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.343800</td>\n",
       "      <td>0.352448</td>\n",
       "      <td>0.921200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.364103</td>\n",
       "      <td>0.918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.332320</td>\n",
       "      <td>0.925600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.295300</td>\n",
       "      <td>0.396726</td>\n",
       "      <td>0.921500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.401248</td>\n",
       "      <td>0.907400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.295500</td>\n",
       "      <td>0.371553</td>\n",
       "      <td>0.920900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.313900</td>\n",
       "      <td>0.382926</td>\n",
       "      <td>0.919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>0.373633</td>\n",
       "      <td>0.918300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.358534</td>\n",
       "      <td>0.921400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.414358</td>\n",
       "      <td>0.918700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.373699</td>\n",
       "      <td>0.915600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.415589</td>\n",
       "      <td>0.912800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.338800</td>\n",
       "      <td>0.357063</td>\n",
       "      <td>0.922600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.312200</td>\n",
       "      <td>0.370570</td>\n",
       "      <td>0.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.286600</td>\n",
       "      <td>0.364594</td>\n",
       "      <td>0.923100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>0.378960</td>\n",
       "      <td>0.923500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.297500</td>\n",
       "      <td>0.332145</td>\n",
       "      <td>0.922700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.269400</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>0.337112</td>\n",
       "      <td>0.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>0.324689</td>\n",
       "      <td>0.923600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.278600</td>\n",
       "      <td>0.412158</td>\n",
       "      <td>0.913100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.267900</td>\n",
       "      <td>0.331310</td>\n",
       "      <td>0.927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>0.369501</td>\n",
       "      <td>0.925100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.308200</td>\n",
       "      <td>0.341027</td>\n",
       "      <td>0.927400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.375982</td>\n",
       "      <td>0.927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.274600</td>\n",
       "      <td>0.386291</td>\n",
       "      <td>0.927400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.395971</td>\n",
       "      <td>0.926900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>0.390960</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>0.384705</td>\n",
       "      <td>0.927400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.222300</td>\n",
       "      <td>0.346657</td>\n",
       "      <td>0.927800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-1000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-1000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-1000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-1500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-1500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-1500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-2000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-2000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-2000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-2500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-2500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-2500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-3000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-3000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-3000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-3500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-3500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-3500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-4000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-4000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-4000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-4500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-4500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-4500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-5000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-5000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-5000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-5500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-5500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-5500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-6000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-6000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-6000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-6500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-6500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-6500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-7000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-7000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-7000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-7500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-7500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-7500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-8000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-8000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-8000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-8500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-8500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-8500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-9000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-9000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-9000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-9500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-9500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-9500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-10000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-10000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-10000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-10500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-10500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-10500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-11000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-11000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-11000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-11500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-11500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-11500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-12000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-12000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-12000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-12500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-12500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-12500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-13000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-13000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-13000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-13500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-13500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-13500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-14000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-14000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-14000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-14500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in D:/reviewsData/result\\checkpoint-14500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-14500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-15000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-15000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-15000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-15500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-15500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-15500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-16000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-16000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-16000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-16500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-16500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-16500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-17000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-17000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-17000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-17500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-17500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-17500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-18000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-18000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-18000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-18500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-18500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-18500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-19000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-19000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-19000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-19500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-19500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-19500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-20000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-20000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-20000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-20500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-20500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-20500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-21000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-21000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-21000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-21500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-21500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-21500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-22000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-22000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-22000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-22500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-22500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-22500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-23000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-23000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-23000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-23500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-23500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-23500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-24000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-24000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-24000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-24500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-24500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-24500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-25000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-25000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-25000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-25500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-25500\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-25500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-26000\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-26000\\config.json\n",
      "Model weights saved in D:/reviewsData/result\\checkpoint-26000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to D:/reviewsData/result\\checkpoint-26500\n",
      "Configuration saved in D:/reviewsData/result\\checkpoint-26500\\config.json\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\caffe2\\serialize\\inline_container.cc:274] . unexpected pos 44224 vs 44142",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1494\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1495\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1556\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1557\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m             \u001b[1;31m# under zero3 model file itself doesn't get saved since it's bogus! Unless deepspeed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(self, output_dir)\u001b[0m\n\u001b[0;32m   1959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1961\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_tpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[0;32m   2007\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2009\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2010\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2011\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[1;34m(self, save_directory, save_config, state_dict, save_function, push_to_hub, **kwargs)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         \u001b[1;31m# If we save using the predefined names, we can load using `from_pretrained`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0moutput_model_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m         \u001b[0msave_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_model_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Model weights saved in {output_model_file}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\caffe2\\serialize\\inline_container.cc:274] . unexpected pos 44224 vs 44142"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the fine tuned model & tokenizer\n",
    "model_path = \"10000-reviews-bert-base-uncased\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    # prepare our text into tokenized sequence\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    # perform inference to our model\n",
    "    outputs = model(**inputs)\n",
    "    # get output probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "    return target_names[probs.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example #1\n",
    "text = \"\"\"\n",
    "The first thing is first. \n",
    "If you purchase a Macbook, you should not encounter performance issues that will prevent you from learning to code efficiently.\n",
    "However, in the off chance that you have to deal with a slow computer, you will need to make some adjustments. \n",
    "Having too many background apps running in the background is one of the most common causes. \n",
    "The same can be said about a lack of drive storage. \n",
    "For that, it helps if you uninstall xcode and other unnecessary applications, as well as temporary system junk like caches and old backups.\n",
    "\"\"\"\n",
    "print(get_prediction(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-49ba3ad177d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtoken_feature_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtoken_feature_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtoken_feature_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtoken_feature_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken_frequency\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'dict' and 'int'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "token_frequency = {'a':11, 'b':1}\n",
    "token_feature = {'a':torch.tensor([1,2,3]), 'b':torch.tensor([3,2,1])}\n",
    "token_feature_list = token_feature.values()\n",
    "token_feature_list = np.array([item.cpu().detach().numpy() for item in token_feature_list])\n",
    "token_feature_list[token_frequency > 10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
